# -*- coding: utf-8 -*-
"""513

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fm5o9qBSBYhyIfOw5qwkH88aNU2_99kq
"""

!pip install xgboost

import pandas as pd
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

import pandas as pd # Make sure pandas is imported with the alias 'pd'
df = pd.read_csv(r"/content/drive/MyDrive/pima-indians-diabetes.data.csv")

df.head()

df.tail()

df.describe()

df.duplicated()

df.isnull().sum()

seed=42
test_size=0.33
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)

# train the model
model = XGBClassifier(learning_rate=0.03)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]
print(predictions)

##accuracy
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

df.shape

#x-y split
x=df.iloc[:,:8] # Selecting columns from 0 to 7 (8 columns total) for features
y=df.iloc[:,8] # Selecting column at index 8 for target variable

seed=42
test_size=0.25
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)

